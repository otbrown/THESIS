In this chapter we will consider some of the theoretical background of many-body and open quantum systems. These are rather broad fields, so we shall focus in particular on aspects that are relevant to the research presented later in this thesis. We will begin by considering what is meant by the word `many' in many-body quantum systems, and why this presents such a challenge to physicists. We will introduce the driven-dissipative Bose-Hubbard model, and physically motivate its terms in the photonic setting, in order to make later chapters more transparent. Then we will discuss what is meant by `open' quantum systems, and discuss how the dynamics of such a system are calculated. Finally we shall discuss how to reformulate these dynamics as a system of coupled linear equations.  

\section{Many-Body Quantum Physics}

\subsection{How many?}
Quantum physics has a problem. More than one actually, but the reader may safely assume that the author considers musing on the interpretation of quantum mechanics to be far above his pay-grade, and that he belongs to the ``Shut up and calculate!'' school of thought \cite{Mermin1989}. What hardship then, does quantum mechanics present to those of us interested only in crunching numbers and getting results? 

To answer that, let us first step back and consider a classical system. Consider some system of \(N\) components, each of which can be in one of two possible states. In total there are \(2^{N}\) possible configurations of the system, each of which can be \emph{completely} described by an \(N\)-bit string. Furthermore, if we increase \(N\) to \(N+m\), we only need to add \(m\) bits. Even if we change to a system where there are three possible states of each component, although the total state space increases in size to \(3^{N}\), since the system must exist in \emph{one and only one} of those configurations, we can still efficiently represent the system with just \(N\) bits. Mathematical representations of many-body classical systems scale linearly with the size of the system (the number of `bodies'). This does not mean that classical many-body problems are \emph{easy}, just that they get harder only in proportion with the size of the system.  

Enter quantum mechanics. We may again consider a system of \(N\) components, each of which can be in one of two possible states, meaning there are \(2^{N}\) possible configurations -- so far, so good. However, there is a fundamental principle of quantum mechanics -- the Superposition principle -- that says that if a system may be in one of two states, which we shall label \(|0 \rangle\) and \(|1\rangle\), then it may also be in the state,
\begin{equation}
	| \psi \rangle = \alpha |0\rangle + \beta |1\rangle,
	\label{eq:mbq1-1}
\end{equation}
where \(\alpha\) and \(\beta\) are complex coefficients. This means that we must replace each of our bits with a complex vector,
\begin{equation}
	|\psi \rangle = \begin{pmatrix}
						\alpha \\
						\beta
					\end{pmatrix},
	\label{eq:mbq1-2}
\end{equation}
where we have arbitrarily chosen a convention that the first element corresponds to \(|0\rangle\), and the second to \(|1\rangle\). Nevertheless, if all that is required to transition to the quantum regime is to replace \(N\) integers to \(2N\) complex floats, this is not so bad. Unfortunately, the superposition principle applies equally to the composite system. Taking \(N=3\), if \(|\Psi\rangle = |000\rangle\) and \(|\Psi\rangle = |111\rangle\) are valid configurations, so is 
\begin{equation}  
	| \Psi \rangle = c_{000}|000 \rangle + c_{111}| 111 \rangle,
	\label{eq:mbq1-3}
\end{equation}
where \(c_{000}\) and \(c_{111}\) are again complex coefficients. In fact, any arbitrary combination of the \(2^{3} = 8\) possible states of the system,
\begin{equation}
	| \Psi \rangle = \sum^{1}_{i,j,k=0} c_{ijk} |ijk \rangle,
	\label{eq:mbq1-4}
\end{equation}
is a valid state, so we must use a vector of 8 complex values to describe the state. More generally, if we have some system of \(N\) quantum components, each of which may be in any combination of \(d\) local states, we require a state vector of \(d^{N}\) complex elements. The representation of the system grows \emph{exponentially} with its size. This scaling problem is the crux of many-body quantum physics \cite{Barnett_MS,NielsenChuang_CS}. To compound the issue, it is also clear that the properties of a many-body system are unlikely to be well predicted by single- or even few-body systems -- it has long been understood that in nature ``more is different'' \cite{Anderson1972}.

\Cref{tab:mbq1-1} provides some examples of how different objects scale in a system with \(d\) local states, and \(N\) sites. The Hamiltonian is an operator which provides an energy description of a quantum system, and generates unitary (non-dissipative) dynamics, but in fact any operator which acts on the many-body quantum state vector will have the same size. The Liouvillian describes the non-unitary dynamics of a quantum system, and is typically written as a super-operator acting on the density matrix, \(\rho\). In order to solve it numerically we re-write it as a system of linear equations acting on the vectorised density matrix, \(|\rho\rangle\rangle\). Since we are primarily interested in stationary states of dissipative systems -- given by solving \(\hat{L}|\rho_{\mathrm{SS}}\rangle\rangle = 0\) -- it is this \(d^{4N}\) element matrix which concerns us the most. It is precisely this very poor exponential scaling that the Matrix Product State technique, described in detail in the next chapter, was designed to defeat. 

\begin{table}[ht!]
	\centering
	\begin{tabu}{lcc}
		\hline
		Object & Symbol & Size \\
		\hline
		State Vector & \(|\Psi\rangle\) & \(d^{N} \times 1\) \\
		Hamiiltonian & \(\hat{H}\) & \(d^{N} \times d^{N}\) \\
		Density Matrix & \(\rho\) & \(d^{N} \times d^{N}\) \\
		Vectorised Density Matrix & \(|\rho \rangle\rangle\) & \(d^{2N} \times 1\) \\
		Liouvillian Matrix & \(\hat{L}\) & \(d^{2N} \times d^{2N}\)
	\end{tabu}
	\caption{\label{tab:mbq1-1}}
\end{table}

\FloatBarrier
\subsection{Driven-dissipative Bose-Hubbard model}
The theme that connects the research presented in this thesis is, of course, the use of matrix product state methods, however it is also true that each of the models is essentially a variant of a driven-dissipative Bose-Hubbard model. As such we will introduce that model here, and then explore two example systems where it \emph{could} be physically implemented. We will pay particular attention to the introduction of an anharmonic energy spectrum, and a carefully engineered dissipative regime, which are of particular importance to the work presented in Ref.~\cite{Brown2018}. The work we present is intended to be independent of implementation, but it can nevertheless be instructive to consider physical systems. Note that the above emphasis on `could' is intentional, we expect actual implementation to be highly challenging. Certainly it would be quite beyond my personal abilities in the laboratory.

The Bose-Hubbard model is a bosonic variant of the electronic Hubbard model first described by John Hubbard in 1963 \cite{Hubbard1963}, and it was first considered by Fisher et al. \cite{Fisher1989}. In the generic case of a one-dimensional lattice of coupled anharmonic oscillators the Bose-Hubbard Hamiltonian is,
\begin{equation}
	\mathcal{H}_{\text{B-H}} = \sum_{j} \left[ \omega\hat{a}_{j}^{\dagger}\hat{a}_{j} + \frac{U}{2}\hat{a}_{j}^{\dagger}\hat{a}_{j}^{\dagger}\hat{a}_{j}\hat{a}_{j} - t\left(\hat{a}_{j}^{\dagger}\hat{a}_{j+1} + \hat{a}_{j}\hat{a}_{j+1}^{\dagger}\right) \right],
	\label{eq:mbq2-1}
\end{equation}
where \(\omega\) is the harmonic oscillator energy, \(U\) is an interaction energy which introduces anharmonicity to the energy spectrum, \(t\) is a hopping rate between sites, the operator \(\hat{a}_{j} (\hat{a}_{j}^{\dagger})\) annihilates (creates) an excitation on the lattice site \(j\), and where we have set \(\hbar = 1\) so that energy is described in units of frequency. We then add a generic coherent drive term,
\begin{equation}
	\mathcal{H}_{\Omega} = \sum_{j} \left[ \left(\Omega\mathrm{e}^{-i\omega_{D}t} + \tilde{\Omega}\mathrm{e}^{i\omega_{D}t}\right) \hat{a}_{j}^{\dagger} + \left(\Omega^{*}\mathrm{e}^{i\omega_{D}t} + \tilde{\Omega}^{*}\mathrm{e}^{-i\omega_{D}t}\right)\hat{a}_{j}\right],
	\label{eq:mbq2-2}
\end{equation}
where \(\Omega\) and \(\tilde{\Omega}\) are drive amplitudes, and \(\omega_{D}\) is the drive frequency. To eliminate the explicit time-dependence of the drive Hamiltonian we would then transform the whole Hamiltonian in to a rotating frame, and make use of the rotating wave approximation which yields,
\begin{equation}
	\mathcal{H} = \sum_{j} \biggl[\Delta\hat{a}_{j}^{\dagger}\hat{a}_{j} + \frac{U}{2}\hat{a}_{j}^{\dagger}\hat{a}_{j}^{\dagger}\hat{a}_{j}\hat{a}_{j} - t\left(\hat{a}_{j}^{\dagger}\hat{a}_{j+1} + \hat{a}_{j}\hat{a}_{j+1}^{\dagger}\right) + \Omega\hat{a}_{j}^{\dagger} + \Omega^{*}\hat{a}_{j} \biggr],
	\label{eq:mbq2-3}
\end{equation}
where \(\Delta = \omega - \omega_{D}\) is the detuning of the drive frequency from the harmonic oscillator frequency. Note that in \cref{chp:rotframe} the rotating frame transformation is shown in detail for the specific parametric driving scheme used in Ref~\cite{Brown2018}, and the procedure here would be the same. Dissipation is introduced to the model through a standard Lindblad form dissipator, which is discussed in the following \cref{sec:OQS}.

Having expressed the model of interest in the most general way possible, we now discuss two possible physical systems.

\subsubsection{Non-linear optical cavity array}
A photonic implementation of the Hamiltonian given in \cref{eq:mbq2-3} necessitates the trapping of light, a feat achieved with an optical cavity. The simplest such system is the Fabry-P\'{e}rot Etalon, a planar cavity consisting of two mirrors with some medium of refractive index \(n\) between \cite{Perot1899,Fox_OC}. Such a system is shown diagramatically in \cref{fig:mbq2-1}. In the limit where the mirrors are perfectly reflective on the sides facing in to the cavity, and there are no absorption or scattering losses in the cavity medium, the light will travel an infinite number of round trips through the cavity and will be totally annihilated unless it is precisely resonant with the cavity length. That is,
\begin{equation}
	\lambda = \frac{2nL_{\mathrm{cav}}}{m},
	\label{eq:mbq2-4}
\end{equation}
where \(m\) is some integer. Under these conditions, the light will be trapped indefinitely in the cavity. This is the canonical `particle in a box' problem, and of course can be treated as a quantum harmonic oscillator. The requirement that there is no absorption or scattering, and perfect reflectivity is physically unrealistic, so it is quite natural to consider such systems in the dissipative regime.

\begin{figure}[ht!]
\centering
\includegraphics[width=0.6\linewidth]{\figpath/FPetalon}
\caption{Diagram of a simple planar cavity. Light enters through the mirror \(M_{1}\) and is then reflected between the two mirrors through some medium with a refractive index \(n\). Here we have assumed that \(M_{1}\) transmits perfectly in to the cavity and then light is perfectly reflected by both \(M_{1}\) and \(M_{2}\). Under this approximation the light is confined indefinitely and travels an infinite distance within the cavity. Only light whose wavelength is resonant with the cavity length, \(\lambda = 2nL_{\mathrm{cav}} / m\) where \(m\) is some integer, will survive under these conditions. Over an infinite number of round trips through the cavity even a small amount of destructive interference will result in total elimination of that wavelength of light. Obviously, real systems have losses in the form of absorption, transmission, and scattering, and will therefore neither perfectly isolate a single wavelength (and its harmonics), nor trap light indefinitely.}
\label{fig:mbq2-1}
\end{figure}

In fact whether the physical origin of the photon loss is absorption or scattering by a mirror or the cavity medium, or by transmission from the cavity is essentially irrelevant to our dynamical equations. All three processes result in a photon leaving the system. In optics the ability of a cavity to retain light is usually referred to as its `quality factor', defined as
\begin{equation}
	\mathcal{Q} = \frac{4\pi L_{\mathrm{cav}}}{\lambda} \frac{1}{-\ln(p)},
	\label{eq:mbq2-5}
\end{equation}
where \(p\) is the fraction of initial power remaining in the cavity after one round trip \cite{Siegman_chp11}. This measure includes loss from all possible sources, and can be exceedingly high in optical microcavities (\(>200\) million \cite{Yang2017}). This is important, as it allows us to reasonably neglect these losses \emph{which we cannot control}. Dissipation which we \emph{can} control is introduced through the Purcell effect.

First presented to the American Physical Society by Edward Purcell in 1946 \cite{Purcell1946}, the Purcell effect is the phenomenon in which spontaneous emission is enhanced (or suppressed) by the presence of a resonant cavity \cite{Fox_Purcell}. The \emph{Purcell factor} is the ratio of spontaneous emission rate in the presence of a second cavity to the original rate, so a purcell factor greater than one implies an enhancement to the spontaneous emission rate. The Purcell factor is proportional to the Q factor of the cavity, and inversely proportional to its modal volume, so smaller cavities with higher Q factors generate larger Purcell factors. In sum, this means that we can \emph{in principle} envision systems in which we are able to tune the dissipation rate on specific transitions -- a key feature of the system we investigate in Ref.~\cite{Brown2018}. Naturally fabrication of such a device while possible \cite{Gerard1998}, is undoubtedly challenging. Be thankful then, that we are theorists.   

Having discussed how light can be trapped in an optical cavity, and how loss rates can be controlled, we are left with four parameters still to be accounted for -- the drive strength \(\Omega\), detuning \(\Delta\), hopping rate \(J\), and interaction strength \(U\).

The physical origin of the drive strength is trivial to consider -- it parameterise the field strength of whatever pump source is used to introduce photons into the system, and is proportional to the amplitude of the incident electromagnetic wave \cite{Fox_Omega}. As noted above \(\Delta = \omega - \omega_{D}\), and in this system \(\omega\) is simply the frequency of the fundamental cavity mode, while \(\omega_{D}\) is the frequency of the pump source. Hopping between cavities (or sites in our lattice) is again easily understood. Confinement perpendicular to the cavity mode is limited and the wavefunction of the trapped light will extend somewhat beyond the cavity boundaries. Placing the cavities in close enough proximity to one another will result in an overlap between the wavefunctions and consequently tunnelling between sites \cite{Hartmann2006,Hartmann2008}. 

Finally, we must consider how to introduce and control non-linearity in our cavity array system, and thus define the interaction strength, \(U\). In principle a term of the form \(\hat{a}^{\dagger 2}\hat{a}^{2}\) appears as a result of the optical Kerr effect in certain materials \cite{Kitagawa1986}, however this effect is third order in the electric susceptibility and therefore requires a high intensity electromagnetic field to become a relevant phenomenon \cite{Boyd_KerrNL}. Another way to introduce nonlinearity is by considering cavities which contain atoms with a four-level structure. Such systems can produce large Kerr-like nonlinearities, as first shown by Schmidt and Imamo\u{g}lu \cite{Schmidt1996}. In fact if we move to considering polaritons (which are photon-atom quasiparticles) then we can construct a full Bose-Hubbard Hamiltonian with even stronger nonlinearity, as detailed in Ref~\cite{Hartmann2008}.

\subsubsection{Superconducting circuits}
Having described how our model of interest may be realised in an optical cavity array, we next consider an alternative superconducting circuit implementation. The fundamental building block of this implementation is an LC circuit which is sufficiently small that both the charge in the capacitor and magnetic flux in the inductor become quantised. Resistance in the circuit would mask quantum effects, so it must be cooled to superconducting temperatures -- on the order of tens of millikelvin. In this regime charge is quantised to units of \(2e\) (where \(e\) is the elementary charge) as the electrons form Cooper pairs \cite{Vool2017,Cooper1956}. However, a quantum LC circuit is still just a quantum harmonic oscillator. To introduce anharmonicity, a Josephson junction must be added to the circuit. Named for Brian David Josephson who first predicted in 1962 that Cooper pairs could tunnel just as single electrons can, a Josephson junction consists of two superconductors separated by a thin insulating barrier \cite{Josephson1962,Schoelkopf2008}. They were first demonstrated by Anderson and Rowell in 1963 \cite{Anderson1963}. 

The Hamiltonian of the LCJ circuit shown in \cref{fig:mbq2-2} is,
\begin{equation}
	\mathcal{H} = 4E_{C}(\hat{n} - n_{g})^{2} - E_{J}\cos(\varphi) + \frac{E_{L}}{2} (\varphi - \varphi_{\mathrm{ext}})^{2},
	\label{eq:mbq2-6}
\end{equation}
where \(\hat{n}\) is the number of Cooper pairs on the Josephson junction, \(n_{g}\) is an offset charge which can be controlled by an externally applied voltage, \(\varphi\) is the phase difference in the superconducting order parameter across the Josephson junction, and \(\varphi_{\mathrm{ext}}\) is proportional to the external flux \(\Phi_{\mathrm{ext}}\) which threads the superconducting loops \cite{Vool2017}. The charging energy \(E_{C}\), Josephson energy \(E_{J}\), and inductive energy \(E_{L}\) are given by,
\begin{align}
	E_{C} &= \frac{e^{2}}{2C}, \label{eq:mbq2-7} \\
	E_{J} &= \frac{\hbar}{2e}I_{0}, \label{eq:mbq2-8} \\
	E_{L} &= \frac{\phi_{0}^{2}}{L}, \label{eq:mbq2-9}
\end{align}
where \(e\) is the elementary charge, \(C\) is the total shunt capacitance, \(I_{0}\) is the critical current of the Josephson junction, \(\phi_{0} = \hbar/2e\) is the reduced flux quantum, and \(L\) is the total shunt inductance \cite{Vool2017,Wendin2017}.

\begin{figure}[ht!]
\centering
\includegraphics[width=0.8\linewidth]{\figpath/JosephsonCircuit}
\caption{\label{fig:mbq2-2}Equivalent circuit for all forms of superconducting circuit qubit. The circuit consists of a Josephon junction (depicted by a box with a cross through it), connected to some shunt capacitor \(C\), and some shunt inductor \(L\). An external flux, \(\Phi_{\mathrm{ext}}\) threads the superconducting loops. \(E_{C}, E_{J},\) and \(E_{L}\) are given by \cref{eq:mbq2-7,eq:mbq2-8,eq:mbq2-9}.}
\end{figure}

The particular quanta of interest in fact depend on the energy parameters in \cref{eq:mbq2-6}, at one extreme when the charging energy is much larger than the Josephson energy, and there is no inductor \((E_{J} / E_{C} \ll 1,\, E_{L} = 0)\) the system forms a `Cooper pair box' or charge qubit, where the relevant degree of freedom is the number of Cooper pairs on one side of the Josephson junction. On the other hand, when the charging energy is small, and the Josephson energy and inductive energy are both large \(( E_{J} / E_{C} \gg 1,\, E_{L} / (E_{J}-E_{L}) \gg 1 )\) the system forms a `flux qubit', where the relevant degree of freedom is the number of flux quanta in the superconducting ring. We will consider in particular one of the possibilities that lies in between these two, the \emph{transmon}.

The transmon is a modification of the Cooper pair box, formed in the regime where again there is no inductor, but unlike the CPB, the Josephson energy is much larger than the charging energy \((E_{J} / E_{C} \gg 1,\, E_{L} = 0)\). The transmon Hamiltonian is then given by,
\begin{equation}
	\mathcal{H}_{\mathrm{transmon}} = 4E_{C}(\hat{n} - n_{g})^{2} - E_{J}\cos(\varphi),
	\label{eq:mbq2-10}
\end{equation}
where we recall that the value of \(n_{g}\) can be controlled through the application of a bias voltage, and that since we intend to use the number of Cooper pairs as our basis (we are still considering a charge qubit) we may ignore the impact of the cosine term. In any case, with more sophisticated set-ups, it is possible to tune the phase parameter with an external flux \cite{Koch2007,Wendin2017}. The principle advantage of the transmon is its relative insensitivity to charge noise compared to the Cooper pair box, although this does come at the cost of a loss of nonlinearity as the bands flatten as \(E_{J}/E_{C} \rightarrow \infty\). Still, it provides the harmonic and anharmonic terms of our desired Hamiltonian \cref{eq:mbq2-3}.

Hopping between sites can be achieved by directly coupling transmon sites together with a capacitor \cite{Wendin2007}, or indirectly via a transmission line cavity \cite{Majer2007}, or a Josephson junction \cite{Chen2014}. The drive term is trivial to consider, as in the optical system, the only difference being that the superconducting circuit is driven at microwave frequencies. Specific dissipative environments can again be engineered through exploitation of the Purcell effect \cite{Purcell1946,Fox_Purcell}.

Having considered the type of model we are interested in, and shown how it could possibly be implemented in two different systems, we will next consider some of the key elements of open quantum systems.

\section{\label{sec:OQS}Open Quantum Systems}

\begin{figure}[ht!]
\centering
\includegraphics[width=0.8\linewidth]{\figpath/open_system}
\caption{The canonical visual representation of an open quantum system. In open quantum systems one considers a composite system, consisting of \(S\), the \emph{system of interest}, here depicted by the blue circle, and \(E\) some well-understood environment -- here depicted by the orange ellipse. The dark blue dashed line marks the interface between the two systems. That the environment is well understood is rather crucial, and often leads to the environment itself being tightly constrained. One does not need to know the state of the environment, but it is necessary to know what states are available, and to be able to precisely define its interaction with the system of interest.}
\label{fig:oqs1-1}
\end{figure}

The study of open quantum systems involves taking a well-behaved closed quantum system, evicting it from the frictionless vacuum every theorist carries in their heart, and embedding it in a noisy environment. The reasons for wanting to do this are obvious -- while the study of energy and number conserving closed quantum systems has lead to many insights, such systems rarely exist. Even a simple pendulum requires consideration of dissipation through friction to describe its real world behaviour.  

In this section we will begin by reminding ourselves of the properties of density matrices, followed by discussion of the Lindblad form master equation, and the approximations inherent to it. Finally, we will discuss some practical details of solving the dynamics of open quantum systems, which will aid in understanding the next chapter on numerical methods.

\subsection{Density Matrix}
The state vector suffices for describing a quantum system which is known to be in one particular state (a \emph{pure} state), but cannot adequately describe a quantum system which may be in one of a number of states. This \emph{ensemble} or \emph{mixed} state must be expressed using the density matrix, commonly denoted by \(\rho\). The density matrix for an ensemble state is defined as,
\begin{equation}
	\rho = \sum_{j} p_{j} |\psi_{j} \rangle \langle \psi_{j}|,
	\label{eq:oqs2-1}
\end{equation}
where \(p_{j} = |c_{j}|^{2}\) is the probability of finding the system in the state \(|\psi_{j}\rangle\), and \(c_{j}\) is the complex amplitude as in \cref{eq:mbq1-4} \cite{NielsenChuang_DM}. A valid density matrix has three important properties,
\begin{align}
	\mathrm{Tr}[\rho] &= 1, \label{eq:oqs2-2} \\
	\rho &= \rho^{\dagger}, \label{eq:oqs2-3} \\
	\langle \psi_{j}| \rho | \psi_{j} \rangle &\geq \, 0 \, \forall \, j, \label{eq:oqs2-4}
\end{align}
its trace is equal to one, it is hermitian, and its diagonal values are all greater-than-or-equal to zero (formally it is \emph{positive semidefinite}). All three can be viewed as consequences of the interpretation of the diagonal values of the density matrix as probabilities for each state. The trace condition is simply the requirement that the probability of the system being in \emph{any} state is one, and the other two ensure that the eigenvalues are real and not-negative, making them valid probabilities.

Observables of the system are calculated by taking the trace of the operator product,
\begin{equation}
	\langle \hat{O} \rangle = \mathrm{Tr}[\hat{O}\rho],
	\label{eq:oqs2-5}
\end{equation}
while the system is time-evolved by applying the operator to both sides of the density matrix,
\begin{align}
	\rho (t) &= \hat{U}(t) \rho(0) \hat{U}^{\dagger}(t), \notag \\
	&= \hat{U}(t) | \Psi(0) \rangle \langle \Psi(0) | \hat{U}^{\dagger}(t),
	\label{eq:oqs2-6}
\end{align}  
where the time-evolution operator \(\hat{U}(t) = \exp(-i\mathcal{H}t)\), and \(\mathcal{H}\) is the system Hamiltonian. Finally, we can calculate the density matrix of a subsystem of a composite system by calculating the \emph{reduced density matrix},
\begin{align}
	\rho^{A} &= \mathrm{Tr}_{B}[\rho^{AB}], \notag \\
	&= \mathrm{Tr}_{B}\left[ c_{j}|a_{j} \rangle \langle a_{k}|c_{k}^{*} \otimes d_{l}|b_{l} \rangle \langle b_{m}|d_{m}^{*} \right], \notag \\
	&= \sum_{n,j,k,l,m}\left[ \langle b_{n} | \left( c_{j}c_{k}^{*}d_{l}d_{m}^{*} |a_{j} \rangle \langle a_{k}| \otimes |b_{l} \rangle \langle b_{m}| \right) | b_{n} \rangle \right], \notag \\ 
	&= \sum_{n,j,k} \left[ c_{j}c_{k}^{*}|d_{n}|^{2} |a_{j} \rangle \langle a_{k}| \otimes \langle b_{n} | b_{n} \rangle \right], \notag \\
	&= \sum_{n,j,k} c_{j}c_{k}^{*}|d_{n}|^{2} |a_{j} \rangle \langle a_{k}|,
	\label{eq:oqs2-7}
\end{align}
where \(|a_{j} \rangle\) and \(|b_{l} \rangle\) are the basis vectors of the \(A\) and \(B\) subsystems respectively, with corresponding complex amplitudes \(c_{j}\) and \(d_{l}\). The replacement of \(l,m,n\) with the single index \(n\), and removal of the tensor product, follows from the orthogonality condition \(\langle b_{l} | b_{m} \rangle = \delta_{lm}\). This ability to separate out subsystems is invaluable to the study of open quantum systems. The system of interest is considered to be part of a composite system with its environment,
\begin{equation}
	\rho = \rho_{S} \otimes \rho_{E},
	\label{eq:oqs2-8}
\end{equation}
where \(\rho_{S}\) is the state of the system of interest, and \(\rho_{E}\) is the state of the environment. The environment can be traced out in order to consider the dynamics of just the system of interest. 

\subsection{\label{sec:lindblad}Lindblad Master Equation}
Throughout our research we will limit ourselves to consideration of master equations of a particular form -- the Lindblad master equation. We will not derive it here, as this can be found in any good text on open quantum systems, such as Breuer and Petruccione's `The Theory of Open Quantum Systems', or Carmichael's `An Open Systems Approach to Quantum Optics' \cite{BP_TMQME,Carmichael_OSAQO}. We shall, however, discuss why the Lindblad form is important, and the approximations that are encoded within it. 

The Lindblad master equation, named for G\"{o}ran Lindblad but based on both his work and that of Gorini, Kossakowski, and Sudarshan \cite{Lindblad1976,Gorini1976}, is as follows,
\begin{equation}
	\frac{\mathrm{d}\rho}{\mathrm{d}t} = -i [\mathcal{H}, \rho] + \sum_{j} \frac{\gamma_{j}}{2} \left[ 2\hat{A}_{j} \rho \hat{A}_{j}^{\dagger} - \left\{\hat{A}_{j}^{\dagger}\hat{A}_{j}, \rho\right\}\right],
	\label{eq:oqs3-1}
\end{equation}
where \(\mathcal{H}\) is the Hamiltonian for the system, the operator \(\hat{A}_{j}\) is the Lindblad operator on the site \(j\), which characterise the interaction between the system and its environment, and the anti-commutator \(\{a, b\} = ab + ba\). The first term is in fact just the Liouville-von Neumann equation, which describes the dynamics of the closed (non-dissipative) system \cite{BP_LvN}. The second term, often referred to as the dissipator,
\begin{equation}
	\mathcal{D}[\rho] = \sum_{j}\frac{\gamma_{j}}{2}\left[2\hat{A}_{j}\rho\hat{A}_{j}^{\dagger} - \left\{\hat{A}_{j}^{\dagger}\hat{A}_{j}, \rho\right\}\right],
	\label{eq:oqs3-2}
\end{equation}
encodes the dissipative dynamics. Importantly, a dissipator of this form preserves both the positivity and trace of the density matrix upon which it operates, ensuring physical results. It is quite general, but does implicitly make the following two approximations.

First, the Born approximation. This approximation assumes that the system-environment interaction is weak. This is reasonable, as we would typically consider anything which interacted strongly as part of the system, rather than the environment. We may therefore neglect terms which are greater than second-order in the interaction Hamiltonian during a power series expansion of the time evolution operator. Specifically we require that,
\begin{equation}
	g \ll \frac{1}{\tau},
	\label{eq:oqs3-3}
\end{equation}
where \(g\) is the interaction energy in units of frequency (when \(\hbar = 1\)), and \(\tau\) is the decay time of correlations in the environment such that,
\begin{equation}
	\langle \hat{a}_{E}(t \geq \tau)\hat{a}_{E}^{\dagger}(0) \rangle \approx 0,
	\label{eq:oqs3-4}
\end{equation}
where \(\hat{a}_{E}(t)\) annihilates an excitation in the environment at time \(t\). 

Second, the Markov approximation. This approximation assumes that the environment is very large, and therefore that any excitations from the system move quickly away from the system-environment interaction centre. Equivalently, one can say that the timescale of significant changes in the state of the system should be much longer than the decay of correlations in the environment (\(\tau\) in \cref{eq:oqs3-4}). This means that excitations cannot return from the environment to the system, and the system's future state is dependent only on its current state, not its history. Specifically, it allows us to approximate the state of the system,
\begin{equation}
	\rho_{S}(t) \approx \tilde{\rho}_{S}(t),
	\label{eq:oqs3-5}
\end{equation}
where,
\begin{align}
	\rho_{S}(t) &= \mathrm{e}^{-i\mathcal{H}(t-s)}\rho_{S}(s)\mathrm{e}^{i\mathcal{H}(t-s)}, \label{eq:oqs3-6} \\
	\tilde{\rho}_{S}(t) &= \mathrm{e}^{-i\mathcal{H_{S}}(t-s)}\rho_{S}(s)\mathrm{e}^{i\mathcal{H}_{S}(t-s)}, \label{eq:oqs3-7}
\end{align}
so that over the integration period the evolution of the system is \emph{approximately} equal to its evolution under only the system Hamiltonian. This approximation also clearly relies on interaction between the system and environment being weak, and is therefore wholly consistent with the Born approximation. For this reason the two are often grouped together as the \emph{Born-Markov approximation} \cite{Hartmann_BM,BP_BMS}.

\subsection{The Liouvillian}
The above section explains how we generate the dynamics of the density matrix, but not we find the stationary state,
\begin{equation}
	\frac{\mathrm{d}}{\mathrm{d}t}\rho_{SS} = 0,
	\label{eq:oqs4-1}
\end{equation}
for this we convert the Lindblad into a system of linear equations, which is named the Liouvillian after its classical counterpart. The Lindblad is a \emph{superoperator}, acting on the density matrix from both the left and the right. In order to rephrase the dynamics as a system of coupled linear equations, we shall make use of the following property of matrix products,
\begin{equation}
	 \mathbf{A}\mathbf{X}\mathbf{B} = \left(\mathbf{B}^{T} \otimes \mathbf{A}\right)\bar{X},
	 \label{eq:oqs4-2}
\end{equation}
 where \(\mathbf{A}, \mathbf{B}\) and \(\mathbf{X}\) are matrices, and \(\bar{X}\) is \(\mathbf{X}\) reshaped into a vector \cite{Macedo2013,Roth1934}. 
 
 In this way the master equation \cref{eq:oqs3-1} is reformulated as the Liouvillian matrix,
 \begin{align}
 	&\hat{L}|\rho \rangle \rangle = \notag \\ 
 	&\quad \left( \mathbb{I} \otimes -i\mathcal{H} + i\mathcal{H}^{T} \otimes \mathbb{I} + \sum_{j} \frac{\gamma_{j}}{2} \left[ \hat{A}_{j}^{*} \otimes 2\hat{A}_{j} - \mathbb{I} \otimes \hat{A}_{j}^{\dagger}\hat{A}_{j} - \hat{A}_{j}^{\dagger}\hat{A}_{j} \otimes \mathbb{I} \right]\right)|\rho\rangle\rangle,
 	\label{eq:oqs4-3}
 \end{align}
 where \(|\rho \rangle\rangle\) is the vectorised density matrix, and \(\mathbb{I}\) is the identity. Our stationary state is then trivially the solution to the system of equations,
 \begin{equation}
 	\hat{L} |\rho_{SS} \rangle\rangle = 0,
 	\label{eq:oqs4-4}
 \end{equation}
 which for a small enough system we can solve directly using linear algebra methods. For larger systems, we make use of Matrix Product States, which will be the main topic of discussion on our next chapter on numerical methods.